{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dependencies and Setting the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloning the Repositories for testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir test_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo '/Users/dhruv/Desktop/Machine_Learning/Projects/Source_Code_Analysis_Application/research/test_repo/.git'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repo.clone_from(\"https://github.com/d-pamneja/Grocery_Store_Application_V2\",to_path=\"./test_repo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Test Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we first only want to check of the APIs built in our test repo\n",
    "\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    \"./test_repo/api\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"], # Will load only python files, remove if you want to load multiple file types\n",
    "    parser= LanguageParser(language=Language.PYTHON,parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def extract_role(user): #A function to extract the role of our user\\n    roles = [role.name for role in user.roles]\\n    return roles[0] if roles else None', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def parse_date(date_string):\\n    if not date_string:\\n        return None\\n    \\n    try:\\n        return datetime.strptime(date_string, \\'%Y-%m-%d\\').date()\\n    except ValueError:\\n        raise ValueError(\"Invalid date format. Expected YYYY-MM-DD.\")', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"class DateToStringField(fields.Raw):\\n    def format(self, value):\\n        return value.strftime('%Y-%m-%d') if value else None\", metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def choice_type(choices):\\n    def choice(arg):\\n        if arg not in choices:\\n            raise ValueError(f\"Value {arg} is not in the allowed choices: {choices}\")\\n        return arg\\n    return choice', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"class UserRoleResource(Resource):\\n    @auth_required('token')\\n    def get(self, user_id):\\n        # Ensure that the logged-in user is the one making the request\\n        if current_user.id != user_id:\\n            return {'error': 'Unauthorized'}, 401\\n\\n        # Fetch the user roles\\n        user = user_model.query.get(user_id)\\n        if user:\\n            roles = [role.name for role in user.roles]\\n            response = {'roles': roles}\\n            return marshal(response, user_roles_fields), 200\\n        else:\\n            return {'error': 'User not found'}, 404\", metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our API file has been loaded and we can see the contents of the file in the documents list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking the Documents via Context-Aware Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap = 200,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = document_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the chunks is : 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the chunks is : {len(texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for the timebeing we are working with a smaller repositery and we have chunked the documents into smaller parts. We can see the first 5 chunks of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def extract_role(user): #A function to extract the role of our user\\n    roles = [role.name for role in user.roles]\\n    return roles[0] if roles else None', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def parse_date(date_string):\\n    if not date_string:\\n        return None\\n    \\n    try:\\n        return datetime.strptime(date_string, \\'%Y-%m-%d\\').date()\\n    except ValueError:\\n        raise ValueError(\"Invalid date format. Expected YYYY-MM-DD.\")', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"class DateToStringField(fields.Raw):\\n    def format(self, value):\\n        return value.strftime('%Y-%m-%d') if value else None\", metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def choice_type(choices):\\n    def choice(arg):\\n        if arg not in choices:\\n            raise ValueError(f\"Value {arg} is not in the allowed choices: {choices}\")\\n        return arg\\n    return choice', metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"class UserRoleResource(Resource):\\n    @auth_required('token')\\n    def get(self, user_id):\\n        # Ensure that the logged-in user is the one making the request\\n        if current_user.id != user_id:\\n            return {'error': 'Unauthorized'}, 401\\n\\n        # Fetch the user roles\\n        user = user_model.query.get(user_id)\\n        if user:\\n            roles = [role.name for role in user.roles]\\n            response = {'roles': roles}\\n            return marshal(response, user_roles_fields), 200\\n        else:\\n            return {'error': 'User not found'}, 404\", metadata={'source': 'test_repo/api/resource.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Documents via OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=()) # Will load the model and disallow or ommit special characters in code base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Knowledge Base or Vector DB using ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./data\"\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Wrapper for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is also important that our llm has the memory of the previous queries and the responses. So, we will create a wrapper for the LLM with a conversation memory as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm = llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will have to also create a wrapper for the conversational retrieval model as well using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    retriever = vectordb.as_retriever(\n",
    "        search_type = \"mmr\", # Here we are using Maximal Marginal Relevance to get the best results, which is a type of search where we get the most relevant results by removing the redundant ones\n",
    "        search_kwargs = {\"k\":3} # Here we are getting the top 3 results\n",
    "    ),\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is the EditCartItemResource class?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SourceCodeAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
